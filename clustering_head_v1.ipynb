{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.spatial.distance import cdist\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make syntetic data\n",
    "\n",
    "# Parameters for data generation\n",
    "n_samples = 200  # Number of data points\n",
    "n_features = 768  # Dimensionality of each data point\n",
    "centers = 4       # Number of clusters\n",
    "cluster_std = 5.0 # Standard deviation to add noise to the clusters\n",
    "noise_level = 30 # Adjust this to control the amount of noise\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_blobs(n_samples=n_samples, \n",
    "                  n_features=n_features, \n",
    "                  centers=centers, \n",
    "                  cluster_std=cluster_std, \n",
    "                  random_state=42)\n",
    "\n",
    "# Adding noise to the data\n",
    "noise = np.random.normal(0, noise_level, X.shape)\n",
    "X_noisy = X + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TreeClusteringClassifier:\n",
    "    def __init__(self, max_clusters=10, min_clusters=2):\n",
    "        self.max_clusters = max_clusters\n",
    "        self.min_clusters = min_clusters\n",
    "        self.kmeans = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.class_names = ['1', '2', '3', '4']\n",
    "        self.class_mapping = None\n",
    "\n",
    "    def find_optimal_clusters(self, embeddings):\n",
    "        silhouette_scores = []\n",
    "        for k in range(self.min_clusters, self.max_clusters + 1):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            cluster_labels = kmeans.fit_predict(embeddings)\n",
    "            silhouette_avg = silhouette_score(embeddings, cluster_labels)\n",
    "            silhouette_scores.append(silhouette_avg)\n",
    "        \n",
    "        optimal_clusters = silhouette_scores.index(max(silhouette_scores)) + self.min_clusters\n",
    "        return optimal_clusters\n",
    "\n",
    "    def train_and_save_model(self, embeddings, labels, model_path, n_splits=5):\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        embeddings_scaled = self.scaler.fit_transform(embeddings)\n",
    "        \n",
    "        best_ari = -1\n",
    "        best_model = None\n",
    "        best_n_clusters = 0\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(embeddings_scaled)):\n",
    "            print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "            \n",
    "            train_embeddings = embeddings_scaled[train_idx]\n",
    "            val_embeddings = embeddings_scaled[val_idx]\n",
    "            val_labels = labels[val_idx]\n",
    "            \n",
    "            n_clusters = self.find_optimal_clusters(train_embeddings)\n",
    "            print(f\"Optimal number of clusters: {n_clusters}\")\n",
    "            \n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "            kmeans.fit(train_embeddings)\n",
    "            \n",
    "            val_predictions = kmeans.predict(val_embeddings)\n",
    "            ari = adjusted_rand_score(val_labels, val_predictions)\n",
    "            print(f\"Fold {fold + 1} Adjusted Rand Index: {ari:.4f}\")\n",
    "            \n",
    "            if ari > best_ari or (ari == best_ari and n_clusters < best_n_clusters):\n",
    "                best_ari = ari\n",
    "                best_model = kmeans\n",
    "                best_n_clusters = n_clusters\n",
    "        \n",
    "        print(f\"Best Adjusted Rand Index: {best_ari:.4f}\")\n",
    "        print(f\"Best number of clusters: {best_n_clusters}\")\n",
    "        self.kmeans = best_model\n",
    "        self.class_mapping = self.map_clusters_to_classes(embeddings, labels)\n",
    "        self.save_model(model_path)\n",
    "\n",
    "    def save_model(self, path):\n",
    "        joblib.dump({'kmeans': self.kmeans, 'scaler': self.scaler, 'class_mapping': self.class_mapping}, path)\n",
    "        print(f\"Model saved to {path}\")\n",
    "\n",
    "    def load_model(self, path):\n",
    "        if os.path.exists(path):\n",
    "            model_data = joblib.load(path)\n",
    "            self.kmeans = model_data['kmeans']\n",
    "            self.scaler = model_data['scaler']\n",
    "            self.class_mapping = model_data['class_mapping']\n",
    "            print(f\"Model loaded from {path}\")\n",
    "        else:\n",
    "            print(f\"No saved model found at {path}\")\n",
    "\n",
    "    def predict(self, embeddings):\n",
    "        if self.kmeans is None:\n",
    "            raise ValueError(\"Model not trained or loaded. Please train or load a model first.\")\n",
    "        embeddings_scaled = self.scaler.transform(embeddings)\n",
    "        cluster_labels = self.kmeans.predict(embeddings_scaled)\n",
    "        distances = cdist(embeddings_scaled, self.kmeans.cluster_centers_, 'euclidean')\n",
    "        probabilities = np.exp(-distances)\n",
    "        probabilities /= probabilities.sum(axis=1, keepdims=True)\n",
    "        return cluster_labels, np.max(probabilities, axis=1)\n",
    "\n",
    "    def predict_with_class_names(self, embeddings):\n",
    "        cluster_labels, probabilities = self.predict(embeddings)\n",
    "        if self.class_mapping is None:\n",
    "            raise ValueError(\"Class mapping not available. Please train or load a model first.\")\n",
    "        predictions = [self.class_mapping.get(label, 'unknown') for label in cluster_labels]\n",
    "        return list(zip(predictions, probabilities))\n",
    "\n",
    "    def map_clusters_to_classes(self, embeddings, labels):\n",
    "        if self.kmeans is None:\n",
    "            raise ValueError(\"Model not trained or loaded. Please train or load a model first.\")\n",
    "        \n",
    "        n_clusters = self.kmeans.n_clusters\n",
    "        class_labels = np.unique(labels)\n",
    "        \n",
    "        cluster_to_classes = {}\n",
    "        for cluster in range(n_clusters):\n",
    "            cluster_indices = np.where(self.kmeans.labels_ == cluster)[0]\n",
    "            cluster_class_labels = labels[cluster_indices]\n",
    "            most_common_class = np.bincount(cluster_class_labels).argmax()\n",
    "            cluster_to_classes[cluster] = self.class_names[most_common_class]\n",
    "        \n",
    "        return cluster_to_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \n",
    "    embeddings = X_noisy\n",
    "    labels = y\n",
    "\n",
    "    classifier = TreeClusteringClassifier(max_clusters=10, min_clusters=2)\n",
    "\n",
    "    classifier.train_and_save_model(embeddings, labels, 'best_tree_clustering_model.joblib')\n",
    "\n",
    "    classifier.load_model('best_tree_clustering_model.joblib')\n",
    "\n",
    "    indices = np.random.choice(len(X), size=100, replace=False)\n",
    "    new_embeddings = X[indices]\n",
    "    \n",
    "    predictions = classifier.predict_with_class_names(new_embeddings)\n",
    "\n",
    "    print(\"\\nPredictions for new data:\")\n",
    "    for i, (class_name, probability) in enumerate(predictions):\n",
    "        print(f\"Sample {i + 1}: Predicted class: {class_name}, Probability: {probability:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
